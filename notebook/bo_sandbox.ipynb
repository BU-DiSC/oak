{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9de5cd-3cf5-433b-828e-04ad277c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datetime\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52dbbadb-dca1-4a2b-8188-cbdbda4d336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7_396, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>receiptdate1</th><th>receiptdate2</th><th>elapsed_0</th><th>elapsed_1</th><th>elapsed_2</th><th>mean_elapsed</th><th>selectivity1</th><th>selectivity2</th></tr><tr><td>i64</td><td>datetime[ms]</td><td>datetime[ms]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>1992-01-03&nbsp;00:00:00</td><td>1992-01-03&nbsp;00:00:00</td><td>0.006372</td><td>0.001012</td><td>0.000931</td><td>0.002771</td><td>1.0</td><td>0.0</td></tr><tr><td>1</td><td>1992-01-03&nbsp;00:00:00</td><td>1992-02-02&nbsp;00:00:00</td><td>0.231195</td><td>0.088566</td><td>0.088825</td><td>0.136195</td><td>1.0</td><td>0.000567</td></tr><tr><td>2</td><td>1992-01-03&nbsp;00:00:00</td><td>1992-03-03&nbsp;00:00:00</td><td>0.193612</td><td>0.157787</td><td>0.157573</td><td>0.169657</td><td>1.0</td><td>0.003764</td></tr><tr><td>3</td><td>1992-01-03&nbsp;00:00:00</td><td>1992-04-02&nbsp;00:00:00</td><td>0.201443</td><td>0.199245</td><td>0.201111</td><td>0.2006</td><td>1.0</td><td>0.010051</td></tr><tr><td>4</td><td>1992-01-03&nbsp;00:00:00</td><td>1992-05-02&nbsp;00:00:00</td><td>0.230072</td><td>0.228478</td><td>0.229138</td><td>0.229229</td><td>1.0</td><td>0.019428</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>7391</td><td>1998-12-27&nbsp;00:00:00</td><td>1998-08-29&nbsp;00:00:00</td><td>0.000568</td><td>0.000582</td><td>0.000557</td><td>0.000569</td><td>0.000004</td><td>0.978716</td></tr><tr><td>7392</td><td>1998-12-27&nbsp;00:00:00</td><td>1998-09-28&nbsp;00:00:00</td><td>0.000556</td><td>0.000566</td><td>0.000572</td><td>0.000564</td><td>0.000004</td><td>0.988609</td></tr><tr><td>7393</td><td>1998-12-27&nbsp;00:00:00</td><td>1998-10-28&nbsp;00:00:00</td><td>0.000571</td><td>0.000582</td><td>0.00056</td><td>0.000571</td><td>0.000004</td><td>0.995406</td></tr><tr><td>7394</td><td>1998-12-27&nbsp;00:00:00</td><td>1998-11-27&nbsp;00:00:00</td><td>0.000557</td><td>0.000567</td><td>0.000569</td><td>0.000564</td><td>0.000004</td><td>0.999114</td></tr><tr><td>7395</td><td>1998-12-27&nbsp;00:00:00</td><td>1998-12-27&nbsp;00:00:00</td><td>0.012798</td><td>0.017295</td><td>0.01322</td><td>0.014437</td><td>0.000004</td><td>0.999996</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7_396, 9)\n",
       "┌──────┬────────────┬────────────┬───────────┬───┬───────────┬────────────┬────────────┬───────────┐\n",
       "│ id   ┆ receiptdat ┆ receiptdat ┆ elapsed_0 ┆ … ┆ elapsed_2 ┆ mean_elaps ┆ selectivit ┆ selectivi │\n",
       "│ ---  ┆ e1         ┆ e2         ┆ ---       ┆   ┆ ---       ┆ ed         ┆ y1         ┆ ty2       │\n",
       "│ i64  ┆ ---        ┆ ---        ┆ f64       ┆   ┆ f64       ┆ ---        ┆ ---        ┆ ---       │\n",
       "│      ┆ datetime[m ┆ datetime[m ┆           ┆   ┆           ┆ f64        ┆ f64        ┆ f64       │\n",
       "│      ┆ s]         ┆ s]         ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "╞══════╪════════════╪════════════╪═══════════╪═══╪═══════════╪════════════╪════════════╪═══════════╡\n",
       "│ 0    ┆ 1992-01-03 ┆ 1992-01-03 ┆ 0.006372  ┆ … ┆ 0.000931  ┆ 0.002771   ┆ 1.0        ┆ 0.0       │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 1    ┆ 1992-01-03 ┆ 1992-02-02 ┆ 0.231195  ┆ … ┆ 0.088825  ┆ 0.136195   ┆ 1.0        ┆ 0.000567  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 2    ┆ 1992-01-03 ┆ 1992-03-03 ┆ 0.193612  ┆ … ┆ 0.157573  ┆ 0.169657   ┆ 1.0        ┆ 0.003764  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 3    ┆ 1992-01-03 ┆ 1992-04-02 ┆ 0.201443  ┆ … ┆ 0.201111  ┆ 0.2006     ┆ 1.0        ┆ 0.010051  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 4    ┆ 1992-01-03 ┆ 1992-05-02 ┆ 0.230072  ┆ … ┆ 0.229138  ┆ 0.229229   ┆ 1.0        ┆ 0.019428  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ …    ┆ …          ┆ …          ┆ …         ┆ … ┆ …         ┆ …          ┆ …          ┆ …         │\n",
       "│ 7391 ┆ 1998-12-27 ┆ 1998-08-29 ┆ 0.000568  ┆ … ┆ 0.000557  ┆ 0.000569   ┆ 0.000004   ┆ 0.978716  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 7392 ┆ 1998-12-27 ┆ 1998-09-28 ┆ 0.000556  ┆ … ┆ 0.000572  ┆ 0.000564   ┆ 0.000004   ┆ 0.988609  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 7393 ┆ 1998-12-27 ┆ 1998-10-28 ┆ 0.000571  ┆ … ┆ 0.00056   ┆ 0.000571   ┆ 0.000004   ┆ 0.995406  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 7394 ┆ 1998-12-27 ┆ 1998-11-27 ┆ 0.000557  ┆ … ┆ 0.000569  ┆ 0.000564   ┆ 0.000004   ┆ 0.999114  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "│ 7395 ┆ 1998-12-27 ┆ 1998-12-27 ┆ 0.012798  ┆ … ┆ 0.01322   ┆ 0.014437   ┆ 0.000004   ┆ 0.999996  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆           ┆            ┆            ┆           │\n",
       "└──────┴────────────┴────────────┴───────────┴───┴───────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_csv('../data/tpch_q12_sweep.csv').rename({'': 'id'})\n",
    "d = pl.read_json('../data/q12_result.json')\n",
    "data = data.with_columns(mean_elapsed=pl.mean_horizontal('elapsed_0', 'elapsed_1', 'elapsed_2'))\n",
    "data = data.with_columns(\n",
    "    pl.col(\"receiptdate1\").str.to_datetime(\"%Y-%m-%d\", time_unit='ms'),\n",
    "    pl.col(\"receiptdate2\").str.to_datetime(\"%Y-%m-%d\", time_unit='ms')\n",
    ")\n",
    "table_rd1 = pl.DataFrame(\n",
    "    {\n",
    "        'receiptdate1': d['sel_receiptdate1'][0].keys(),\n",
    "        'selectivity1': d['sel_receiptdate1'][0].values()\n",
    "    }\n",
    ").with_columns(pl.col(\"receiptdate1\").str.to_datetime(\"%Y-%m-%d\", time_unit='ms'))\n",
    "table_rd2 = pl.DataFrame(\n",
    "    {\n",
    "        'receiptdate2': d['sel_receiptdate2'][0].keys(),\n",
    "        'selectivity2': d['sel_receiptdate2'][0].values()\n",
    "    }\n",
    ").with_columns(pl.col(\"receiptdate2\").str.to_datetime(\"%Y-%m-%d\", time_unit='ms'))\n",
    "data = data.join(table_rd1, on='receiptdate1').join(table_rd2, on='receiptdate2')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0bc37c-58d1-40f8-9b6f-ead559565320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (29_070, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row1_id</th><th>row2_id</th><th>slope</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>49.143525</td></tr><tr><td>0</td><td>86</td><td>3.71849</td></tr><tr><td>0</td><td>87</td><td>23.907892</td></tr><tr><td>1</td><td>2</td><td>1.245692</td></tr><tr><td>1</td><td>86</td><td>182.73971</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>7390</td><td>7391</td><td>1.005479</td></tr><tr><td>7391</td><td>7392</td><td>1.007602</td></tr><tr><td>7392</td><td>7393</td><td>1.011122</td></tr><tr><td>7393</td><td>7394</td><td>1.011407</td></tr><tr><td>7394</td><td>7395</td><td>25.583016</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (29_070, 3)\n",
       "┌─────────┬─────────┬───────────┐\n",
       "│ row1_id ┆ row2_id ┆ slope     │\n",
       "│ ---     ┆ ---     ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ f64       │\n",
       "╞═════════╪═════════╪═══════════╡\n",
       "│ 0       ┆ 1       ┆ 49.143525 │\n",
       "│ 0       ┆ 86      ┆ 3.71849   │\n",
       "│ 0       ┆ 87      ┆ 23.907892 │\n",
       "│ 1       ┆ 2       ┆ 1.245692  │\n",
       "│ 1       ┆ 86      ┆ 182.73971 │\n",
       "│ …       ┆ …       ┆ …         │\n",
       "│ 7390    ┆ 7391    ┆ 1.005479  │\n",
       "│ 7391    ┆ 7392    ┆ 1.007602  │\n",
       "│ 7392    ┆ 7393    ┆ 1.011122  │\n",
       "│ 7393    ┆ 7394    ┆ 1.011407  │\n",
       "│ 7394    ┆ 7395    ┆ 25.583016 │\n",
       "└─────────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviation_log = d['deviation_log'][0]\n",
    "table_dev = pl.DataFrame({'deviation': d['deviation_log'][0]}).with_columns(pl.col(\"deviation\").list.to_struct()).unnest(\"deviation\")\n",
    "table_dev = table_dev.rename(\n",
    "        {'field_0': 'row1_id',\n",
    "        'field_1': 'row2_id',\n",
    "        'field_2': 'slope'}\n",
    "    ).with_columns(pl.col('row1_id').cast(pl.Int64), pl.col('row2_id').cast(pl.Int64))\n",
    "table_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5afe42-8b82-4a6a-b0f2-31c95d31f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tables:\n",
    "    def __init__(self, table_data, table_dev):\n",
    "        self.data = table_data\n",
    "        self.dev = table_dev\n",
    "\n",
    "    def closest_row_idx(self, date_a, date_b, table=None):\n",
    "        dist = lambda col_a, col_b: abs(col_a - date_a) + abs(col_b - date_b)\n",
    "        if table is None:\n",
    "            table = self.data\n",
    "        idx = table.select((dist(pl.col('receiptdate1'), pl.col('receiptdate2'))).arg_min()).item()\n",
    "        return table[idx]['id'].item()\n",
    "        \n",
    "    def objfunc(self, date_a: datetime.datetime, date_b: datetime.datetime, rho=datetime.timedelta(days=30)):\n",
    "        idx = self.closest_row_idx(date_a, date_b)\n",
    "        dates_moved = (date_a + rho, date_b + rho)\n",
    "        neighbors = self.data.join(self.dev.filter(pl.col('row1_id') == idx), left_on='id', right_on='row2_id')\n",
    "        perturb_idx = self.closest_row_idx(dates_moved[0], dates_moved[1], neighbors)\n",
    "\n",
    "        return self.dev.filter((pl.col('row1_id') == idx) & (pl.col('row2_id') == perturb_idx))[0]['slope'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad09f72-2c56-4a77-acdd-e5fd3b46ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = Tables(data, table_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c3b891-b1aa-4db3-8c1f-dd4065be3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = tables.closest_row_idx(d1, d2)\n",
    "# t = data.join(table_dev.filter(pl.col('row1_id') == idx), left_on='id', right_on='row2_id')\n",
    "# perturb_idx = tables.closest_row_idx(d1, d2, t)\n",
    "# table_dev.filter((pl.col('row1_id') == idx) & (pl.col('row2_id') == perturb_idx))[0]['slope']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243492fc-0937-4173-8bb4-41a8f9569744",
   "metadata": {},
   "source": [
    "# Training Initial GP\n",
    "\n",
    "We'll select 10 starting points to train our GP model initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a66ad7-4bd0-4230-b515-36e257f1b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>receiptdate1</th><th>receiptdate2</th><th>elapsed_0</th><th>elapsed_1</th><th>elapsed_2</th><th>mean_elapsed</th><th>selectivity1</th><th>selectivity2</th><th>target</th></tr><tr><td>i64</td><td>datetime[ms]</td><td>datetime[ms]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2523</td><td>1994-05-22&nbsp;00:00:00</td><td>1994-05-22&nbsp;00:00:00</td><td>0.097777</td><td>0.094962</td><td>0.095217</td><td>0.095985</td><td>0.669451</td><td>0.330549</td><td>1.000414</td></tr><tr><td>402</td><td>1992-05-02&nbsp;00:00:00</td><td>1996-10-08&nbsp;00:00:00</td><td>0.707456</td><td>0.705814</td><td>0.701288</td><td>0.704853</td><td>0.980572</td><td>0.69217</td><td>1.001481</td></tr><tr><td>1745</td><td>1993-08-25&nbsp;00:00:00</td><td>1994-01-22&nbsp;00:00:00</td><td>0.523571</td><td>0.402537</td><td>0.305702</td><td>0.410603</td><td>0.781618</td><td>0.280699</td><td>1.110342</td></tr><tr><td>4767</td><td>1996-07-10&nbsp;00:00:00</td><td>1995-01-17&nbsp;00:00:00</td><td>0.000595</td><td>0.000616</td><td>0.00059</td><td>0.0006</td><td>0.345229</td><td>0.430328</td><td>1.034799</td></tr><tr><td>4407</td><td>1996-03-12&nbsp;00:00:00</td><td>1993-09-24&nbsp;00:00:00</td><td>0.000648</td><td>0.000693</td><td>0.000719</td><td>0.000687</td><td>0.395114</td><td>0.23085</td><td>1.131596</td></tr><tr><td>2298</td><td>1994-02-21&nbsp;00:00:00</td><td>1997-02-05&nbsp;00:00:00</td><td>0.613757</td><td>0.649611</td><td>0.611688</td><td>0.625018</td><td>0.706843</td><td>0.742046</td><td>1.010462</td></tr><tr><td>7380</td><td>1998-12-27&nbsp;00:00:00</td><td>1997-10-03&nbsp;00:00:00</td><td>0.000573</td><td>0.000558</td><td>0.00057</td><td>0.000567</td><td>0.000004</td><td>0.841835</td><td>1.01177</td></tr><tr><td>4131</td><td>1995-12-13&nbsp;00:00:00</td><td>1992-04-02&nbsp;00:00:00</td><td>0.000652</td><td>0.000685</td><td>0.000627</td><td>0.000655</td><td>0.432507</td><td>0.010051</td><td>1.095624</td></tr><tr><td>3044</td><td>1994-11-18&nbsp;00:00:00</td><td>1994-10-19&nbsp;00:00:00</td><td>0.000599</td><td>0.000586</td><td>0.000592</td><td>0.000592</td><td>0.594611</td><td>0.39292</td><td>1.034703</td></tr><tr><td>5813</td><td>1997-07-05&nbsp;00:00:00</td><td>1996-03-12&nbsp;00:00:00</td><td>0.000563</td><td>0.000562</td><td>0.000566</td><td>0.000564</td><td>0.195572</td><td>0.604886</td><td>1.070351</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 10)\n",
       "┌──────┬────────────┬────────────┬───────────┬───┬────────────┬────────────┬────────────┬──────────┐\n",
       "│ id   ┆ receiptdat ┆ receiptdat ┆ elapsed_0 ┆ … ┆ mean_elaps ┆ selectivit ┆ selectivit ┆ target   │\n",
       "│ ---  ┆ e1         ┆ e2         ┆ ---       ┆   ┆ ed         ┆ y1         ┆ y2         ┆ ---      │\n",
       "│ i64  ┆ ---        ┆ ---        ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ f64      │\n",
       "│      ┆ datetime[m ┆ datetime[m ┆           ┆   ┆ f64        ┆ f64        ┆ f64        ┆          │\n",
       "│      ┆ s]         ┆ s]         ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "╞══════╪════════════╪════════════╪═══════════╪═══╪════════════╪════════════╪════════════╪══════════╡\n",
       "│ 2523 ┆ 1994-05-22 ┆ 1994-05-22 ┆ 0.097777  ┆ … ┆ 0.095985   ┆ 0.669451   ┆ 0.330549   ┆ 1.000414 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 402  ┆ 1992-05-02 ┆ 1996-10-08 ┆ 0.707456  ┆ … ┆ 0.704853   ┆ 0.980572   ┆ 0.69217    ┆ 1.001481 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 1745 ┆ 1993-08-25 ┆ 1994-01-22 ┆ 0.523571  ┆ … ┆ 0.410603   ┆ 0.781618   ┆ 0.280699   ┆ 1.110342 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 4767 ┆ 1996-07-10 ┆ 1995-01-17 ┆ 0.000595  ┆ … ┆ 0.0006     ┆ 0.345229   ┆ 0.430328   ┆ 1.034799 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 4407 ┆ 1996-03-12 ┆ 1993-09-24 ┆ 0.000648  ┆ … ┆ 0.000687   ┆ 0.395114   ┆ 0.23085    ┆ 1.131596 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 2298 ┆ 1994-02-21 ┆ 1997-02-05 ┆ 0.613757  ┆ … ┆ 0.625018   ┆ 0.706843   ┆ 0.742046   ┆ 1.010462 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 7380 ┆ 1998-12-27 ┆ 1997-10-03 ┆ 0.000573  ┆ … ┆ 0.000567   ┆ 0.000004   ┆ 0.841835   ┆ 1.01177  │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 4131 ┆ 1995-12-13 ┆ 1992-04-02 ┆ 0.000652  ┆ … ┆ 0.000655   ┆ 0.432507   ┆ 0.010051   ┆ 1.095624 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 3044 ┆ 1994-11-18 ┆ 1994-10-19 ┆ 0.000599  ┆ … ┆ 0.000592   ┆ 0.594611   ┆ 0.39292    ┆ 1.034703 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "│ 5813 ┆ 1997-07-05 ┆ 1996-03-12 ┆ 0.000563  ┆ … ┆ 0.000564   ┆ 0.195572   ┆ 0.604886   ┆ 1.070351 │\n",
       "│      ┆ 00:00:00   ┆ 00:00:00   ┆           ┆   ┆            ┆            ┆            ┆          │\n",
       "└──────┴────────────┴────────────┴───────────┴───┴────────────┴────────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = (\n",
    "    tables.data\n",
    "    .sample(10)\n",
    "    .with_columns(\n",
    "        pl.struct('receiptdate1', 'receiptdate2')\n",
    "        .map_elements(lambda row: tables.objfunc(row['receiptdate1'], row['receiptdate2']), return_dtype=pl.Float64)\n",
    "        .alias('target')\n",
    "    )\n",
    ")\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ec106b7-921f-454b-b556-4142158161c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.6956e+11, 7.6956e+11], dtype=torch.float64),\n",
       " tensor([1.0004], dtype=torch.float64))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = samples.select('receiptdate1', 'receiptdate2').cast(pl.Float64).to_torch()\n",
    "train_y = samples.select('target').to_torch()\n",
    "train_x[0], train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d556bce7-7e36-482f-8cde-e71dd3a64405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): RBFKernel(\n",
       "      (lengthscale_prior): LogNormalPrior()\n",
       "      (raw_lengthscale_constraint): GreaterThan(2.500E-02)\n",
       "    )\n",
       "    (outcome_transform): Standardize()\n",
       "    (input_transform): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = SingleTaskGP(\n",
    "    train_X=train_x,\n",
    "    train_Y=train_y,\n",
    "    input_transform=Normalize(d=len(train_x[0])),\n",
    "    outcome_transform=Standardize(m=1),\n",
    ")\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd5ca0-16a0-4dc8-96c8-3aef85688b76",
   "metadata": {},
   "source": [
    "### Acquisition Function\n",
    "\n",
    "For now, as our GP estimates the slope from two queries we will directly try to maximize this value.\n",
    "\n",
    "The bounds will allow us to control the area in which we search, this is where we can decide how to divide up the search space.\n",
    "\n",
    "We can try something dumb where we search over the whole space for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d366c85-bf2b-47cb-bd55-90ddd2ff44d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[751962887855, 753596844714]]), tensor(-4.4586, dtype=torch.float64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = torch.stack([\n",
    "    torch.concat([\n",
    "        data.select(pl.col('receiptdate1', 'receiptdate2').min()).cast(pl.Float64).to_torch().flatten(), # minimum bounds for query 1\n",
    "    ]),\n",
    "    torch.concat([\n",
    "        data.select(pl.col('receiptdate1', 'receiptdate2').max()).cast(pl.Float64).to_torch().flatten(), # maximum bounds for query 1\n",
    "    ]),\n",
    "]).to(torch.double)\n",
    "\n",
    "logNEI = LogExpectedImprovement(model=gp, best_f=train_y.max())\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    logNEI, bounds=bounds, q=1, num_restarts=1, raw_samples=100,\n",
    ")\n",
    "candidate = candidate.round().to(torch.int64) # Note we round off the item as we're dealing in ms\n",
    "candidate, acq_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05e75e-4ca7-4310-9357-6fbef92f3e68",
   "metadata": {},
   "source": [
    "Once we have the candidate we rebuild the query into something we could potentially pass into the DB\n",
    "\n",
    "TODO: we will want to map the closest query to this for experimentation, however, we will need to round to the nearest whole number as we're dealing in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c299b8d1-0d62-45d4-9ec9-c69f21719529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'receiptdate1': datetime.datetime(1993, 10, 30, 2, 34, 47),\n",
       " 'receiptdate2': datetime.datetime(1993, 11, 17, 23, 27, 24)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For some reason datetime does not take in ms, so we'll convert to seconds losing a little more precision\n",
    "query = {\n",
    "    'receiptdate1': datetime.datetime.fromtimestamp(candidate[0][0].item() // 1000), # datetime ms -> s\n",
    "    'receiptdate2': datetime.datetime.fromtimestamp(candidate[0][1].item() // 1000), # datetime ms -> s\n",
    "}\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96b1ed-7183-475f-8488-bc209e4d1423",
   "metadata": {},
   "source": [
    "## Gaining feedback by running on the DB\n",
    "\n",
    "Now we have some queries to test, we can run it back on the DB to gain feedback on whether or not this worked out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a831d32-4356-404d-ba71-318b178622db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5dc8187-fa05-430a-91ed-ccd17e61ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBWrapperTpchQ12:\n",
    "    def __init__(self, db_path: str) -> None:\n",
    "        con = duckdb.connect(database=db_path)\n",
    "        con.execute('SET enable_progress_bar = false')\n",
    "        self.con: duckdb.DuckDBPyConnection = con\n",
    "        self.query_template = \"\"\"\n",
    "            SELECT\n",
    "              l_shipmode,\n",
    "              SUM(CASE\n",
    "                  WHEN o_orderpriority = '1-URGENT'\n",
    "                      OR o_orderpriority = '2-HIGH'\n",
    "                      THEN 1\n",
    "                  ELSE 0\n",
    "              END) as high_line_count,\n",
    "              SUM(CASE\n",
    "                  WHEN o_orderpriority <> '1-URGENT'\n",
    "                      AND o_orderpriority <> '2-HIGH'\n",
    "                      THEN 1\n",
    "                  ELSE 0\n",
    "              END) AS low_line_count\n",
    "            FROM\n",
    "                orders,\n",
    "                lineitem\n",
    "            WHERE\n",
    "              o_orderkey = l_orderkey\n",
    "              AND l_shipmode IN ('AIR', 'REG AIR')\n",
    "              AND l_commitdate < l_receiptdate\n",
    "              AND l_shipdate < l_commitdate\n",
    "              AND l_receiptdate >= $receiptdate1\n",
    "              AND l_receiptdate < $receiptdate2\n",
    "            GROUP BY\n",
    "                  l_shipmode \n",
    "            ORDER BY\n",
    "                l_shipmode;\n",
    "        \"\"\"\n",
    "\n",
    "    def run_query(self, predicates: dict):\n",
    "        start = time.time()\n",
    "        self.con.sql(self.query_template, params=predicates)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fbd3aea-dda3-4860-aca0-b9cb432ed717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qerror(a, b):\n",
    "    return max(a/b, b/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfbbc3a3-1451-46cb-ba55-ad24b6637662",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBWrapperTpchQ12(db_path='../data/tpch_sf100.db')\n",
    "perturb_query = {\n",
    "    'receiptdate1': query['receiptdate1'] + datetime.timedelta(days=30),\n",
    "    'receiptdate2': query['receiptdate2'] + datetime.timedelta(days=30),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08b1fbe8-fee8-47ea-9dae-c06c7a99c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = db.run_query(query)\n",
    "b = db.run_query(perturb_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aef8320a-bc5b-4665-8235-a33591441034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0371761330485236"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_qerror(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fa208-1873-42e4-b750-d37746046fb5",
   "metadata": {},
   "source": [
    "# Doing the training loop\n",
    "\n",
    "With one point of feedback, we can now do the whole training loop. Simply placing back the data point we just got into the original dataset and rebuilding the new GP model we can incorporate this new piece of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f78650-a8dd-4c8a-9c25-2bbd29e5f418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
